{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import dotenv\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "openai.api_key = os.getenv(\"OPEN_AI_API\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.llms import OpenAI \n",
    "from langchain.chains import ConversationChain\n",
    "\n",
    "history = ChatMessageHistory()\n",
    "llm = OpenAI(openai_api_key=openai.api_key,temperature=0)\n",
    "memory = ConversationSummaryBufferMemory(llm=llm,max_token_limit=100)\n",
    "conversation = ConversationChain(\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    memory=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: what was I asking you about?\n",
      "AI:  You were asking me about the weather forecast for tomorrow.\n",
      "Human: what I?\n",
      "AI:  You asked me what the weather forecast for tomorrow is.\n",
      "Human: cappital of India\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      " The capital of India is New Delhi.\n"
     ]
    }
   ],
   "source": [
    "result = conversation.predict(input=\"cappital of India\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" The keys of the dictionary object returned by conversation.predict(input=) are 'text', 'probability', and 'temperature'.\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "llm = OpenAI(openai_api_key=openai.api_key,temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vision_tools import what_am_i_holding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.tools import BaseTool\n",
    "class WhatAmIHolding(BaseTool):\n",
    "    name = \"hand contents\"\n",
    "    description = \"useful when you need to answer questions about what is in my hands or what am I holding\"\n",
    "    def _run(self ,query:str ) -> str:\n",
    "        return what_am_i_holding()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [WhatAmIHolding()]\n",
    "agent = initialize_agent(\n",
    "    tools, llm, agent=AgentType.CHAT_ZERO_SHOT_REACT_DESCRIPTION,  verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: I need to research what a Large Language Model is\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"research\",\n",
      "  \"action_input\": \"Large Language Model\"\n",
      "}\n",
      "```\n",
      "\u001b[0m\n",
      "Observation: research is not a valid tool, try one of [hand contents].\n",
      "Thought:\u001b[32;1m\u001b[1;3m I should use the hand contents tool to answer this question\n",
      "Action:\n",
      "```\n",
      "{\n",
      "  \"action\": \"hand contents\",\n",
      "  \"action_input\": \"\"\n",
      "}\n",
      "```\n",
      "\n",
      "\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mYou are holding a Cup in your right hand\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m A Large Language Model is not a physical object, so it is not in my hand\n",
      "Final Answer: A Large Language Model is a type of artificial intelligence (AI) system that uses deep learning techniques to process large amounts of natural language data. It is used to generate natural language text, identify sentiment, and understand the context of conversations.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A Large Language Model is a type of artificial intelligence (AI) system that uses deep learning techniques to process large amounts of natural language data. It is used to generate natural language text, identify sentiment, and understand the context of conversations.'"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.run('what is a Large Language Model?')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
